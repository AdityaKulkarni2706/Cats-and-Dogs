{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Goal : To build a CNN-Classifier which can classify whether inputted image is a cat or a dog\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Image Detection and Recognition\\training_set\\training_set\"\n",
    "test_path = r\"C:\\Image Detection and Recognition\\test_set\\test_set\"\n",
    "\n",
    "#Below variables are only for visualisation\n",
    "\n",
    "train_dogs = r\"training_set\\dogs\"\n",
    "train_cats = r\"training_set\\cats\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of ImageDataGenerator is done, which basically is a tool to convert Image Data into dimensional arrays, which has various parameters for image generation to prevent overfitting for CNNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generator is an object, to get the actual data, flow_from_directory function is used, which is an iterator and will read the data in a usable form for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "   \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of:\n",
    "\n",
    "1) 32-neuron Convolution Layer\n",
    "2) 64-neuron Convolution Layer\n",
    "3) 128-neuron Convolution Layer\n",
    "4) 512-neuron Dense Layer\n",
    "5) Output Layer\n",
    "\n",
    "The first 4 layers have sub-layers which are required to tackle with overfitting,which are Max Pooling Layers.\n",
    "\n",
    "Overfitting prevention measures such as Batch Normalisation and Dropout are used in every main layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 74, 74, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 36, 36, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 17, 17, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36992)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               18940416  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,035,073\n",
      "Trainable params: 19,034,625\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        # LAYER 1\n",
    "\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # LAYER 2\n",
    "\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # LAYER 3\n",
    "\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        # FINAL LAYER : Dense Layer + Output Layer\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "model.build(input_shape=(150,150,3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 52s 175ms/step - loss: 3.6905 - accuracy: 0.5991 - val_loss: 1.1388 - val_accuracy: 0.5704\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.6903 - accuracy: 0.6808 - val_loss: 0.6485 - val_accuracy: 0.6925\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 41s 162ms/step - loss: 0.5698 - accuracy: 0.7167 - val_loss: 0.5538 - val_accuracy: 0.7475\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.5334 - accuracy: 0.7321 - val_loss: 0.6306 - val_accuracy: 0.7391\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.5236 - accuracy: 0.7421 - val_loss: 0.8758 - val_accuracy: 0.7282\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.4993 - accuracy: 0.7538 - val_loss: 0.4989 - val_accuracy: 0.7659\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 47s 186ms/step - loss: 0.4937 - accuracy: 0.7603 - val_loss: 0.5410 - val_accuracy: 0.7490\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.4734 - accuracy: 0.7780 - val_loss: 0.5034 - val_accuracy: 0.7495\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.4700 - accuracy: 0.7833 - val_loss: 0.9363 - val_accuracy: 0.7078\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4585 - accuracy: 0.7897 - val_loss: 0.4978 - val_accuracy: 0.7798\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.4421 - accuracy: 0.7957 - val_loss: 0.5337 - val_accuracy: 0.7624\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4302 - accuracy: 0.7988 - val_loss: 0.4999 - val_accuracy: 0.7902\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.4182 - accuracy: 0.8070 - val_loss: 0.5088 - val_accuracy: 0.7674\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.4214 - accuracy: 0.8099 - val_loss: 0.4718 - val_accuracy: 0.7832\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.4101 - accuracy: 0.8196 - val_loss: 0.4884 - val_accuracy: 0.7847\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4080 - accuracy: 0.8174 - val_loss: 0.5696 - val_accuracy: 0.7684\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.3882 - accuracy: 0.8228 - val_loss: 0.5672 - val_accuracy: 0.7862\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3815 - accuracy: 0.8352 - val_loss: 0.7442 - val_accuracy: 0.7212\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 41s 165ms/step - loss: 0.3701 - accuracy: 0.8395 - val_loss: 0.4867 - val_accuracy: 0.7981\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.3523 - accuracy: 0.8460 - val_loss: 0.5588 - val_accuracy: 0.7922\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 0.3655 - accuracy: 0.8440 - val_loss: 0.5725 - val_accuracy: 0.7837\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 40s 160ms/step - loss: 0.3465 - accuracy: 0.8539 - val_loss: 0.4792 - val_accuracy: 0.8259\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.3211 - accuracy: 0.8609 - val_loss: 0.5246 - val_accuracy: 0.7981\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.3283 - accuracy: 0.8588 - val_loss: 0.4763 - val_accuracy: 0.7684\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.3193 - accuracy: 0.8604 - val_loss: 0.5797 - val_accuracy: 0.7703\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.3090 - accuracy: 0.8647 - val_loss: 0.4015 - val_accuracy: 0.8304\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.3060 - accuracy: 0.8692 - val_loss: 0.4116 - val_accuracy: 0.8274\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.2917 - accuracy: 0.8796 - val_loss: 0.4152 - val_accuracy: 0.8229\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.2746 - accuracy: 0.8839 - val_loss: 0.5448 - val_accuracy: 0.7996\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.2759 - accuracy: 0.8840 - val_loss: 0.4370 - val_accuracy: 0.8418\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.2733 - accuracy: 0.8855 - val_loss: 0.4436 - val_accuracy: 0.8289\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.2644 - accuracy: 0.8938 - val_loss: 0.4121 - val_accuracy: 0.8140\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.2490 - accuracy: 0.8958 - val_loss: 0.4487 - val_accuracy: 0.8403\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.2502 - accuracy: 0.8997 - val_loss: 0.7465 - val_accuracy: 0.7857\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.2543 - accuracy: 0.8967 - val_loss: 0.3896 - val_accuracy: 0.8497\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.2518 - accuracy: 0.9010 - val_loss: 0.4054 - val_accuracy: 0.8492\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.2335 - accuracy: 0.9081 - val_loss: 0.4418 - val_accuracy: 0.8175\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.2358 - accuracy: 0.9061 - val_loss: 0.3843 - val_accuracy: 0.8358\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.2323 - accuracy: 0.9059 - val_loss: 0.6082 - val_accuracy: 0.8145\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.2325 - accuracy: 0.9067 - val_loss: 0.3636 - val_accuracy: 0.8403\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.2242 - accuracy: 0.9127 - val_loss: 1.4195 - val_accuracy: 0.7356\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.2157 - accuracy: 0.9145 - val_loss: 0.4121 - val_accuracy: 0.8452\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.1948 - accuracy: 0.9222 - val_loss: 0.3625 - val_accuracy: 0.8571\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.2058 - accuracy: 0.9214 - val_loss: 0.4061 - val_accuracy: 0.8452\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.2067 - accuracy: 0.9177 - val_loss: 0.4606 - val_accuracy: 0.8472\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.1918 - accuracy: 0.9260 - val_loss: 0.4099 - val_accuracy: 0.8408\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.1975 - accuracy: 0.9207 - val_loss: 0.4879 - val_accuracy: 0.8333\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.2035 - accuracy: 0.9196 - val_loss: 0.3697 - val_accuracy: 0.8552\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.1821 - accuracy: 0.9320 - val_loss: 0.3778 - val_accuracy: 0.8566\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.1779 - accuracy: 0.9300 - val_loss: 0.4054 - val_accuracy: 0.8790\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 0.4042 - accuracy: 0.8794\n",
      "Test Accuracy : 0.88\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
    "    epochs = 50,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = test_generator.samples//test_generator.batch_size\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy : {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.title(f\"Label : {int(y_batch[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for visualising how the model's accuracy is when its measured on the training data vs when its measured on the testing data. When the gap between training accuracy and validation (testing) accuracy is significant, its a sign of overfitting. In this project, the model overfits the data, however, it still has a validation accuracy of about 85%. It surely can be optimised by processes like data augmentation, but this project is intended to give myself an insight of how convolutional neural networks work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], color = 'blue', label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for saving the model, and using it directly for predictions : Main purpose being that it would be useful to load up the model and make a web UI for practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
